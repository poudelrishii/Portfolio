# -*- coding: utf-8 -*-
"""Customer_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-qgDx_WkJP32Nln-lQqDwrHZwnkBSoL_

\# Do You Know Your Customer?- A Brief Customer Analysis

Background

Objective

Data Dictionary

Part 1- Data Loading

Part 2- Data Cleaning and Verification

Part 3- Data Exploration

# Background

In a business, multiple types of customer may buy the product. Companies may have a general understanding of who their customer are. But when a indepth research is made, several interesting insights are found about the customers. By understanding the ideal customers on a deeper level, company can tailor their products to meet their unique needs, behaviors, and preferences. This analysis will identify different elements of most promising customer segment.
This will ultimately help the company to improve their performance.

# Objective
*   Which kind of family is buying for your product?
*   Are their any special pattern in consumer buying behavious?
*   How much customers are willing to pay for the products?

# Data Dictionary

People
ID: Customer's unique identifier>
People
* ID: Customer's unique identifier
* Year_Birth: Customer's birth year
* Marital_Status: Customer's marital status
* Income: Customer's yearly household income
* Education: Customer's education level
* Kidhome: Number of children in customer's household
* Teenhome: Number of teenagers in customer's household
* Dt_Customer: Date of customer's enrollment with the company
* Recency: Number of days since customer's last purchase
* Complain: 1 if the customer complained in the last 2 years, 0 otherwise

Products
* MntWines: Amount spent on wine in last 2 years
* MntFruits: Amount spent on fruits in last 2 years
* MntMeatProducts: Amount spent on meat in last 2 years
* MntFishProducts: Amount spent on fish in last 2 years
* MntSweetProducts: Amount spent on sweets in last 2 years
* MntGoldProds: Amount spent on gold in last 2 years

Place
* NumWebPurchases: Number of purchases made through the company’s website
* NumCatalogPurchases: Number of purchases made using a catalogue
* NumStorePurchases: Number of purchases made directly in stores
* NumWebVisitsMonth: Number of visits to company’s website in the last month

Promotion
* NumDealsPurchases: Number of purchases made with a discount
* AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise
* AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise
* AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise
* AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise
* AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise
* Response: 1 if customer accepted the offer in the last campaign, 0 otherwise

Place

* NumWebPurchases: Number of purchases made through the company’s website
* NumCatalogPurchases: Number of purchases made using a catalogue
* NumStorePurchases: Number of purchases made directly in stores
* NumWebVisitsMonth: Number of visits to company’s website in the last month

# Part 1: Data Loading

## 1.1 Mount data to google drive
"""

#Mount the raw data to googledrive
#Data from Kaggle
from google.colab import drive
drive.mount('/content/drive')

"""## 1.2 Import Libraries"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

"""## 1.3 Upload CSV files"""

#import pandas library for data analysis
#import csv file for analysis
import csv
csv_file_path = '/content/drive/MyDrive/43031/Project/Customer_Personality_Analysis.csv'

# Read the CSV file
data = pd.read_csv(csv_file_path, sep="\t")

# Display the first few rows of the dataset
data.head()

"""# Part 2- Data Cleaning and Verification (Lowercase, Filter, Missing values, Outliers, Duplicates)

## **2.1 Data Information (Data types, Null, Column Headers)**
"""

#Data information( Column Name, Type, Null Values)
print(data.info())

#NUmber of Null Values
print(data.isnull().sum())

"""## **2.2 Median Refill on Missing Values**"""

# Calculate the median income
median_income = data['Income'].median()

# Impute missing income values with the median
data['Income'].fillna(median_income, inplace=True)

print(data.isnull().sum())

"""***Medain value is used to refill the missing income values because it is less sensitive to outliers***

## **2.3 Count Number of Rows and Column**
"""

#calculating total rows and columns before data filtering
num_rows = data.shape[0]
num_columns = data.shape[1]

print(f"Number of rows: {num_rows}")
print(f"Number of columns: {num_columns}")

"""## **2.4 Datapoints into lowercase transformation**"""

#Categorical datatypes changed into lowercase....
string_columns = data.select_dtypes(include=['object']).columns

for column in string_columns:
    data[column] = data[column].str.lower()

"""## **2.5 Change Data Types**


"""

# Convert to Categorical
for col in ['Education', 'Marital_Status', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Response']:
    data[col] = data[col].astype('category')

# Convert to Numerical
data['Income'] = pd.to_numeric(data['Income'], errors='coerce')

"""## **2.6 Display Data**"""

# Display the top 5 rows
print("Top 5 rows:")
print(data.head())

# Display the bottom 5 rows
print("\nBottom 5 rows:")
print(data.tail())

"""## **2.7 Identify and Display Duplicate Rows and Columns**"""

# Check for duplicate rows and columns
print("Duplicate rows:", data.duplicated().sum())
print("Duplicate columns:", data.T.duplicated().sum())

print(data.dtypes)

"""## 2.8 Outliers Using Box Plot"""

numeric_columns_spending =['MntWines', 'Income', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']
numeric_columns_others = ['Age', 'Kidhome', 'Teenhome', 'Recency', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']

fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# Box plot for spending data
data[numeric_columns_spending].boxplot(ax=axes[0], rot=90)
axes[0].set_title('Box Plot of Spending Data')
axes[0].set_xlabel('Spending Features')
axes[0].set_ylabel('Values')
axes[0].tick_params(axis='x', rotation=90)

# Box plot for other numerical data
data[numeric_columns_others].boxplot(ax=axes[1], rot=90)
axes[1].set_title('Box Plot of Other Numerical Data')
axes[1].set_xlabel('Other Numerical Features')
axes[1].set_ylabel('Values')
axes[1].tick_params(axis='x', rotation=90)

# Adjust layout
plt.tight_layout()
plt.show()

"""## 2.9 Remove Outliers"""

# Remove outliers using IQR
def remove_outliers(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

# Remove outliers for spending and other numerical data
data_spending = remove_outliers(data.copy(), numeric_columns_spending)
data_others = remove_outliers(data.copy(), numeric_columns_others)

# Create side-by-side box plots
fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# Box plot for spending data
data_spending[numeric_columns_spending].boxplot(ax=axes[0], rot=90)
axes[0].set_title('Box Plot of Spending Data')
axes[0].set_xlabel('Spending Features')
axes[0].set_ylabel('Values')
axes[0].tick_params(axis='x', rotation=90)

# Box plot for other numerical data
data_others[numeric_columns_others].boxplot(ax=axes[1], rot=90)
axes[1].set_title('Box Plot of Other Numerical Data')
axes[1].set_xlabel('Other Numerical Features')
axes[1].set_ylabel('Values')
axes[1].tick_params(axis='x', rotation=90)

# Adjust layout
plt.tight_layout()
plt.show()

"""## 2.10 Feature Engineering (Derive New Variables)"""

#create new variable age
current_year = pd.Timestamp.now().year
data['Age'] = current_year - data['Year_Birth']

#create new variable total spending
#Spending Categories
Total_Spending = ["MntWines", "MntFruits", "MntMeatProducts", "MntFishProducts", "MntSweetProducts", "MntGoldProds"]

# Categorization of Marital_Status
data_feature=data
marital_status_index = {"Married": 1, "Together": 1, "Absurd": 0, "Widow": 0, "YOLO": 0, "Divorced": 0, "Single": 0}
data_feature["partner"] = data["Marital_Status"].map(marital_status_index).fillna(0).astype(int)

# Catagorization of Education
data_feature["Education"] = data["Education"].replace({"basic": "Undergraduate", "2n Cycle": "Undergraduate", "graduation": "Graduate", "master": "Postgraduate", "phD": "PhD"})

#Catagorization of Total family size

# Calculate total family size
data_feature['Total_Family_Size'] = data_feature['Kidhome'] + data_feature['Teenhome'] + data_feature['partner']+1

# Calculate total spending
data_feature['Total_Spending'] = data_feature['MntWines'] + data_feature['MntFruits'] + data_feature['MntMeatProducts'] + data_feature['MntFishProducts'] + data_feature['MntSweetProducts'] + data_feature['MntGoldProds']

# Creating new dataset called final_data
included_variables = ['Age','Education','Income', 'Recency', 'Complain' ]  # All variables except spending and family size

# Create a new DataFrame with the included variables and calculated features
final_data = data[included_variables + ['Total_Spending', 'Total_Family_Size']].copy()

# Display the new DataFrame
print(final_data.head())

"""## **2.11 Clean Data Set for Exploration**"""

# Clean Data Set created for the data exploration
# Create a copy of the final dataset as data_cleaned
data_clean = final_data.copy()

"""# **Part 3- Data Exploration**

## 3.1 Sum and Average of Numerical Variables
"""

import numpy as np

numerical_columns = data_clean.select_dtypes(include=[np.number])

# Calculate sum
sum_table = numerical_columns.sum()

# Average calculation, formatted to 1 decimal place
average_table = numerical_columns.mean().round(1)

# Combine sum and average into a single DataFrame
summary_table = pd.DataFrame({'Sum': sum_table, 'Average': average_table})

# Display the summary table
print("Summary of Numerical Columns (Sum and Average):")
print(summary_table)

"""## 3.2 Summary Statistics"""

# Summary statistics
summary_stat = data_clean.describe().round(2)

# Table Display
print("\nSummary statistics ")
print(summary_stat.to_string())

"""## 3.3 Coorelation Matrix"""

# Calculation of the correlation matrix
corr_matrix = data_clean.select_dtypes(include=['int64', 'float64']).corr()

# Healt Map
plt.figure(figsize=(10,5))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Heatmap of Numerical Columns')
plt.show()

"""Income has significant impact on spending. Also the family size has significant negative impact on spending.

## 3.4 Data Distribution
"""

#data distribution of variables

import matplotlib.pyplot as plt

# Plot histograms
numerical_columns = data_clean.select_dtypes(include='number').columns

# Set up the subplot grid
num_plots = len(numerical_columns)
num_cols = 3
num_rows = -(-num_plots // num_cols)
fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))

# Flatten axes if there's only one row
if num_rows == 1:
    axes = [axes]

# Plot histograms
for i, column in enumerate(numerical_columns):
    row_index = i // num_cols
    col_index = i % num_cols
    ax = axes[row_index][col_index]
    data_clean[column].plot(kind='hist', bins=20, ax=ax)
    ax.set_title(column)
    ax.set_xlabel('Value')
    ax.set_ylabel('Frequency')

# Remove empty subplots
for i in range(num_plots, num_rows * num_cols):
    row_index = i // num_cols
    col_index = i % num_cols
    fig.delaxes(axes[row_index][col_index])

# Adjust layout
plt.tight_layout()
plt.show()

"""# Part 4- Data Analysis

## 4.1 Spending By Category
"""

import matplotlib.pyplot as plt

# Calculate total spending for each category
category_spending = data[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']].sum()

# Plot bar chart
plt.figure(figsize=(10, 6))
category_spending.plot(kind='bar', color='darkblue', edgecolor='black')
plt.title('Customer Spending Pattern by Category')
plt.xlabel('Category')
plt.ylabel('Total Spending')
plt.xticks(rotation=45)
plt.grid(False)
plt.show()

"""## 4.2 Spending Pattern (How much are customers willing to spend?"""

# Plot histogram of total spending
plt.figure(figsize=(10, 6))
plt.hist(data_clean['Total_Spending'], bins=20, color='darkblue', edgecolor='black')
plt.title('Distribution of Total Spending')
plt.xlabel('Total Spending')
plt.ylabel('Frequency')
plt.grid(False)
plt.show()

"""Customers significantly spend upto 150 dollars . The frequency of spending decreases as the total spending amount gets higher.

## 4.3 Education Affect Spending ?
"""

import seaborn as sns

# Calculate average spending for each education level
education_spending = data.groupby('Education')[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']].mean()

# Plot the relationship between education and spending
plt.figure(figsize=(10, 6))
sns.heatmap(education_spending, cmap='viridis', annot=True, fmt=".2f")
plt.title('Relationship between Education and Spending')
plt.xlabel('Spending Category')
plt.ylabel('Education Level')
plt.show()

"""Individuals with Phd spends the most on wine products, followed by meat products. Simillarly, undergraduate smests almost same on wines sweets and gold. Graduates also spend most on wines followed by meat products.

Interestingly, customers with basic education is very much into fish products compared to other education level of other customers.

## 4.4 Family Size Affect Spending ?
"""

import matplotlib.pyplot as plt

# Calculate average total spending for each family size
avg_spending_by_family_size = data_clean.groupby('Total_Family_Size')['Total_Spending'].mean()

# Plot line graph
plt.figure(figsize=(10, 6))
plt.plot(avg_spending_by_family_size.index, avg_spending_by_family_size.values, marker='o', color='red', linestyle='-')
plt.title('Average Total Spending by Family Size')
plt.xlabel('Total Family Size')
plt.ylabel('Average Total Spending')
plt.xticks(rotation=45)
plt.grid(False)

# Add annotation
max_spending_family_size = avg_spending_by_family_size.idxmax()
max_spending = avg_spending_by_family_size.max()
plt.annotate(f'Max spending at Family Size {max_spending_family_size} ({max_spending:.2f})',
             xy=(max_spending_family_size, max_spending),
             xytext=(max_spending_family_size + 0.1, max_spending - 200),
             arrowprops=dict(facecolor='black', arrowstyle='->'),
             horizontalalignment='left')

plt.show()

"""Single individual spends more on items compared to family.

## 4.5 Income Affects Spending ?
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import linregress

# Function to remove outliers based on specified column
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Remove outliers from 'Income' and 'Total_Spending' columns
data_cleaned_no_outliers = remove_outliers(data_cleaned, 'Income')
data_cleaned_no_outliers = remove_outliers(data_cleaned_no_outliers, 'Total_Spending')

# Fit a linear regression line
slope, intercept, r_value, p_value, std_err = linregress(data_cleaned_no_outliers['Income'], data_cleaned_no_outliers['Total_Spending'])
x_values = np.linspace(data_cleaned_no_outliers['Income'].min(), data_cleaned_no_outliers['Income'].max(), 100)
y_values = slope * x_values + intercept

# Plot scatter plot with trend line
plt.figure(figsize=(10, 6))
sns.scatterplot(data=data_cleaned_no_outliers, x='Income', y='Total_Spending', color='skyblue', alpha=0.7)
plt.plot(x_values, y_values, color='red', linestyle='--', label='Trendline')
plt.title('Scatter Plot with Trendline: Income vs Total Spending (Outliers Removed)')
plt.xlabel('Income')
plt.ylabel('Total Spending')
plt.legend()
plt.grid(True)
plt.show()

"""## 4.6 Complaints Affects Spending?"""

import matplotlib.pyplot as plt

# Calculate average total spending for customers with and without complaints
avg_spending_with_complaints = data_cleaned[data_cleaned['Complain'] == 1]['Total_Spending'].mean()
avg_spending_without_complaints = data_cleaned[data_cleaned['Complain'] == 0]['Total_Spending'].mean()

# Create bar chart
plt.figure(figsize=(8, 6))
plt.bar(['With Complaints', 'Without Complaints'], [avg_spending_with_complaints, avg_spending_without_complaints], color=['blue', 'green'])
plt.title('Average Total Spending with and without Complaints')
plt.xlabel('Complaints')
plt.ylabel('Average Total Spending')
plt.show()

"""## 4.7 Recency Affects Spending?"""

import matplotlib.pyplot as plt

# Plot scatter plot between recency and total spending
plt.figure(figsize=(10, 6))
plt.scatter(data_cleaned['Recency'], data_cleaned['Total_Spending'], color='blue', alpha=0.7)
plt.title('Scatter Plot: Recency vs Total Spending')
plt.xlabel('Recency')
plt.ylabel('Total Spending')
plt.grid(True)
plt.show()

"""No real relationship observed

# Part 5- Conclusion and Recommendation

The summary of major findings are

1. Customer spends most on wine products followed by meat products and then gold products.
2. Customers mostly buy wine products, followed by meat products which are the significant sales compared to other sales
3. Most number of customers are willing to spend less than 150 dollars

4. Phd students spends the most on wine products and then on meat products. Undergraduates are exceptional case of spenders becuase they mostly buy gold products and are the lowest consumer of wine products.

  Interestingly, customers with basic level of education are the primary type of customer for fish products compared to other education level

5. Single individual spends more on items compared to family.

6. More income leads to more spending. And the relationship is linear.

7. Customers with complaints spends less on items

8. Recency has no relationship with spending

Future Recommendations

1. Indepth analysis of spending pattern on each categoy can be conducted

2. Using these variables a predictive model can be built
"""